import torch
from datasets import load_dataset
from Tools import load_model_and_tokenizer, prepare_dataset, setup_trainer, update_config, parse_args
import argparse
import sys

# --- é»˜è®¤é…ç½® ---
config = {
    "model_name": "Qwen/Qwen1.5-7B-Chat",
    "dataset_name": "dongSHE/MindChat-R0-FT-Data",
    "lora": {
        "r": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "bias": "none",
        "use_dora": True,
        "task_type": "CAUSAL_LM",
        "target_modules": [
            "q_proj", "k_proj", "v_proj", "o_proj",
            "gate_proj", "up_proj", "down_proj"
        ]
    },
    "training": {
        "output_dir": "./mindchat-qwen1.5-7b-finetuned",
        "num_train_epochs": 1,
        "per_device_train_batch_size": 1,
        "gradient_accumulation_steps": 8,
        "learning_rate": 1e-4,
        "logging_steps": 10,
        "optim": "paged_adamw_8bit",
        "bf16": True,
        "gradient_checkpointing": True,
    },
    "quantization": {
        "load_in_4bit": True,
        "bnb_4bit_quant_type": "nf4",
        "bnb_4bit_compute_dtype": torch.bfloat16,
        "bnb_4bit_use_double_quant": True,
    }
}

# --- ä¸»æ‰§è¡Œæµç¨‹ ---
def main():
    """ä¸»å‡½æ•°ï¼Œä¸²è”æ•´ä¸ªå¾®è°ƒæµç¨‹ã€‚"""
    
    args = parse_args()
    final_config = update_config(config, args)

    print("ğŸš€ å¼€å§‹æ‰§è¡Œ MindChat å¾®è°ƒæµç¨‹ ğŸš€")
    print(" final_config:",final_config)
    
    model, tokenizer = load_model_and_tokenizer(
        final_config["model_name"], 
        final_config["quantization"]
    )
    
    dataset = prepare_dataset(
        final_config["dataset_name"], 
        tokenizer
    )
    
    trainer = setup_trainer(
        model, 
        tokenizer, 
        dataset, 
        final_config["lora"], 
        final_config["training"]
    )

    print("\nğŸ”¥ å¼€å§‹æ¨¡å‹å¾®è°ƒ... ğŸ”¥")
    trainer.train()
    print("ğŸ‰ æ¨¡å‹å¾®è°ƒå®Œæˆï¼")

    final_output_dir = final_config["training"]["output_dir"]
    print(f"... æ­£åœ¨å°†è®­ç»ƒå¥½çš„ Adapter ä¿å­˜åˆ° {final_output_dir} ...")
    trainer.save_model(final_output_dir)
    print("âœ… Adapter ä¿å­˜æˆåŠŸï¼")

if __name__ == "__main__":
    main()